{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RajuMopidevi/Applied-ML/blob/main/Mini_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeGqYFuPDv7G"
      },
      "source": [
        "<table class=\"table table-bordered\">\n",
        "    <tr>\n",
        "        <th style=\"text-align:center; width:25%\"><img src='https://www.nus.edu.sg/images/default-source/base/logo.png' style=\"width: 250px; height: 125px; \"></th>\n",
        "        <th style=\"text-align:center;\"><h1>Applied Machine Learning</h1><h2>Mini Project </h2><h3></h3></th>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For Google Colaboratory\n",
        "import sys, os\n",
        "if 'google.colab' in sys.modules:\n",
        "    # mount google drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "    path_to_file = '/content/gdrive/My Drive/Applied_ML/Practical' # Please adjust the path accordingly\n",
        "    os.chdir(path_to_file)\n",
        "    !pwd"
      ],
      "metadata": {
        "id": "qmN-Njj1D_kC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a230915e-0ae9-4b46-b41c-aa68006bafff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/Applied_ML/Practical\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EVUInlEHDv7K"
      },
      "outputs": [],
      "source": [
        "# Import the requried packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import linear_model, neighbors, tree, svm, ensemble\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JldKCp2pDv7M"
      },
      "source": [
        "You will be using the bank marketing campaign data to build classification model. The dataset (`bank.csv`) gives you information about a marketing campaign done by a financial institution. Detailed information (i.e. column description) is provided below. We are trying to predict whether the customer/client will deposit the money into the bank or not?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w73WQYyTDv7M"
      },
      "source": [
        " * **age :**  age in years\n",
        " * **job :**  type of job\n",
        " * **marital :**  marital status\n",
        " * **education :**  education background\n",
        " * **default :**  has credit in default?\n",
        " * **balance :**  Balance of the individual\n",
        " * **housing :**  has housing loan?\n",
        " * **loan :**  has personal loan?\n",
        " * **contact :**  contact communication type\n",
        " * **day :**  last contact day of the week\n",
        " * **month :**  last contact month of year\n",
        " * **duration :**  last contact duration, in seconds\n",
        " * **campaign :**  number of contacts performed during this campaign and for this client\n",
        " * **pdays :**  number of days that passed by after the client was last contacted from a previous campaign\n",
        " * **previous :**  number of contacts performed before this campaign and for this client\n",
        " * **poutcome :**  outcome of the previous marketing campaign\n",
        " * <font color='red'> **deposit :** has the client subscribed a term deposit? This is the TARGET variable </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJ0LAlnDDv7M"
      },
      "source": [
        "We have provided data preprocessing codes per below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5YUsjEGDv7N",
        "outputId": "c4dccc4b-1cc6-4095-cf3b-7a0bf3311ab2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   age         job  marital  education default  balance housing loan  contact  \\\n",
            "0   59      admin.  married  secondary      no     2343     yes   no  unknown   \n",
            "1   56      admin.  married  secondary      no       45      no   no  unknown   \n",
            "2   41  technician  married  secondary      no     1270     yes   no  unknown   \n",
            "3   55    services  married  secondary      no     2476     yes   no  unknown   \n",
            "4   54      admin.  married   tertiary      no      184      no   no  unknown   \n",
            "\n",
            "   day month  duration  campaign  pdays  previous poutcome deposit  \n",
            "0    5   may      1042         1     -1         0  unknown     yes  \n",
            "1    5   may      1467         1     -1         0  unknown     yes  \n",
            "2    5   may      1389         1     -1         0  unknown     yes  \n",
            "3    5   may       579         1     -1         0  unknown     yes  \n",
            "4    5   may       673         2     -1         0  unknown     yes  \n",
            "job :\n",
            "Index(['admin.', 'blue-collar', 'entrepreneur', 'housemaid', 'management',\n",
            "       'retired', 'self-employed', 'services', 'student', 'technician',\n",
            "       'unemployed', 'unknown'],\n",
            "      dtype='object')\n",
            "marital :\n",
            "Index(['divorced', 'married', 'single'], dtype='object')\n",
            "education :\n",
            "Index(['primary', 'secondary', 'tertiary', 'unknown'], dtype='object')\n",
            "default :\n",
            "Index(['no', 'yes'], dtype='object')\n",
            "housing :\n",
            "Index(['no', 'yes'], dtype='object')\n",
            "loan :\n",
            "Index(['no', 'yes'], dtype='object')\n",
            "contact :\n",
            "Index(['cellular', 'telephone', 'unknown'], dtype='object')\n",
            "month :\n",
            "Index(['apr', 'aug', 'dec', 'feb', 'jan', 'jul', 'jun', 'mar', 'may', 'nov',\n",
            "       'oct', 'sep'],\n",
            "      dtype='object')\n",
            "poutcome :\n",
            "Index(['failure', 'other', 'success', 'unknown'], dtype='object')\n",
            "deposit :\n",
            "Index(['no', 'yes'], dtype='object')\n",
            "   age  job  marital  education  default  balance  housing  loan  contact  \\\n",
            "0   59    0        1          1        0     2343        1     0        2   \n",
            "1   56    0        1          1        0       45        0     0        2   \n",
            "2   41    9        1          1        0     1270        1     0        2   \n",
            "3   55    7        1          1        0     2476        1     0        2   \n",
            "4   54    0        1          2        0      184        0     0        2   \n",
            "\n",
            "   day  month  duration  campaign  pdays  previous  poutcome  deposit  \n",
            "0    5      8      1042         1     -1         0         3        1  \n",
            "1    5      8      1467         1     -1         0         3        1  \n",
            "2    5      8      1389         1     -1         0         3        1  \n",
            "3    5      8       579         1     -1         0         3        1  \n",
            "4    5      8       673         2     -1         0         3        1  \n"
          ]
        }
      ],
      "source": [
        "# Loading the data\n",
        "bank = pd.read_csv('https://raw.githubusercontent.com/RajuMopidevi/Applied-ML/main/Practical/bank.csv')\n",
        "print(bank.head())\n",
        "# Encode the categorical data into numbers\n",
        "bank_cat = bank.select_dtypes(['object']).copy()\n",
        "for col in bank_cat:\n",
        "    print(col, ':')\n",
        "    codes, uniques = pd.factorize(bank_cat[col], sort=True)\n",
        "    bank[col]=codes\n",
        "    print(uniques)\n",
        "print(bank.head())\n",
        "\n",
        "# Set the \"deposit\" as target/model output and the rest features as model inputs\n",
        "y = bank['deposit']\n",
        "X = bank.drop(['deposit'], axis=1)\n",
        "\n",
        "# Split the data into training and testing data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n",
        "\n",
        "#Sacaling the data into a smaller range (-3 to +3)\n",
        "mean = X_train.mean()\n",
        "std = X_train.std()\n",
        "\n",
        "X_train = (X_train - mean) / std\n",
        "X_test = (X_test - mean) / std\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "K57yx3N51Cvr",
        "outputId": "b34c3fcd-7418-42ed-837a-981fcaa4721a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            age       job   marital  education   default   balance   housing  \\\n",
              "10713  0.311590 -1.399276 -0.323496   2.287973 -0.119149  0.150938 -0.942781   \n",
              "8431   1.233067 -1.399276 -0.323496  -1.715942 -0.119149 -0.415907  1.060573   \n",
              "9060   0.730443 -0.467874  1.274123  -0.381304 -0.119149 -0.231086 -0.942781   \n",
              "8604   1.400608 -1.399276 -0.323496  -0.381304 -0.119149 -0.025215  1.060573   \n",
              "2988   0.144049 -0.157407  1.274123   0.953334 -0.119149  3.202795 -0.942781   \n",
              "...         ...       ...       ...        ...       ...       ...       ...   \n",
              "1099  -1.028739  1.705397  1.274123  -1.715942 -0.119149 -0.308172 -0.942781   \n",
              "2514  -1.531363  1.084462  1.274123  -0.381304 -0.119149 -0.345013 -0.942781   \n",
              "6637  -0.191033 -0.157407 -0.323496   0.953334 -0.119149 -0.478442  1.060573   \n",
              "2575   1.568149 -1.399276 -0.323496  -0.381304 -0.119149 -0.445627 -0.942781   \n",
              "7336  -0.107263 -1.399276 -1.921114  -0.381304 -0.119149 -0.393617  1.060573   \n",
              "\n",
              "           loan   contact       day     month  duration  campaign     pdays  \\\n",
              "10713 -0.389825 -0.598686  1.463949  0.806711 -0.939404  0.531137 -0.479882   \n",
              "8431  -0.389825  1.845607 -0.797574  0.806711 -0.565266 -0.192912 -0.479882   \n",
              "9060  -0.389825  0.623460  1.463949 -0.444320 -0.896235 -0.554937 -0.479882   \n",
              "8604   2.564968  1.845607 -1.273684  0.181196 -0.925014  9.581747 -0.479882   \n",
              "2988  -0.389825 -0.598686 -1.392711 -1.069836  1.285282  0.893161  1.778920   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "1099  -0.389825 -0.598686  1.582977 -0.444320  1.227722 -0.554937 -0.479882   \n",
              "2514  -0.389825 -0.598686 -0.321464 -1.382594  0.349935 -0.192912 -0.479882   \n",
              "6637  -0.389825 -0.598686 -0.559519  0.806711 -0.755213 -0.554937 -0.479882   \n",
              "2575  -0.389825 -0.598686  0.630757 -1.382594 -0.455902  0.169112  0.375303   \n",
              "7336   2.564968 -0.598686  1.106867 -0.131562 -0.925014  0.531137 -0.479882   \n",
              "\n",
              "       previous  poutcome  \n",
              "10713 -0.375551  0.518328  \n",
              "8431  -0.375551  0.518328  \n",
              "9060  -0.375551  0.518328  \n",
              "8604  -0.375551  0.518328  \n",
              "2988   0.083679 -0.485173  \n",
              "...         ...       ...  \n",
              "1099  -0.375551  0.518328  \n",
              "2514  -0.375551  0.518328  \n",
              "6637  -0.375551  0.518328  \n",
              "2575   0.083679 -0.485173  \n",
              "7336  -0.375551  0.518328  \n",
              "\n",
              "[8929 rows x 16 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d1f5db60-0930-4b33-9ddf-871989145ca0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>job</th>\n",
              "      <th>marital</th>\n",
              "      <th>education</th>\n",
              "      <th>default</th>\n",
              "      <th>balance</th>\n",
              "      <th>housing</th>\n",
              "      <th>loan</th>\n",
              "      <th>contact</th>\n",
              "      <th>day</th>\n",
              "      <th>month</th>\n",
              "      <th>duration</th>\n",
              "      <th>campaign</th>\n",
              "      <th>pdays</th>\n",
              "      <th>previous</th>\n",
              "      <th>poutcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10713</th>\n",
              "      <td>0.311590</td>\n",
              "      <td>-1.399276</td>\n",
              "      <td>-0.323496</td>\n",
              "      <td>2.287973</td>\n",
              "      <td>-0.119149</td>\n",
              "      <td>0.150938</td>\n",
              "      <td>-0.942781</td>\n",
              "      <td>-0.389825</td>\n",
              "      <td>-0.598686</td>\n",
              "      <td>1.463949</td>\n",
              "      <td>0.806711</td>\n",
              "      <td>-0.939404</td>\n",
              "      <td>0.531137</td>\n",
              "      <td>-0.479882</td>\n",
              "      <td>-0.375551</td>\n",
              "      <td>0.518328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8431</th>\n",
              "      <td>1.233067</td>\n",
              "      <td>-1.399276</td>\n",
              "      <td>-0.323496</td>\n",
              "      <td>-1.715942</td>\n",
              "      <td>-0.119149</td>\n",
              "      <td>-0.415907</td>\n",
              "      <td>1.060573</td>\n",
              "      <td>-0.389825</td>\n",
              "      <td>1.845607</td>\n",
              "      <td>-0.797574</td>\n",
              "      <td>0.806711</td>\n",
              "      <td>-0.565266</td>\n",
              "      <td>-0.192912</td>\n",
              "      <td>-0.479882</td>\n",
              "      <td>-0.375551</td>\n",
              "      <td>0.518328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9060</th>\n",
              "      <td>0.730443</td>\n",
              "      <td>-0.467874</td>\n",
              "      <td>1.274123</td>\n",
              "      <td>-0.381304</td>\n",
              "      <td>-0.119149</td>\n",
              "      <td>-0.231086</td>\n",
              "      <td>-0.942781</td>\n",
              "      <td>-0.389825</td>\n",
              "      <td>0.623460</td>\n",
              "      <td>1.463949</td>\n",
              "      <td>-0.444320</td>\n",
              "      <td>-0.896235</td>\n",
              "      <td>-0.554937</td>\n",
              "      <td>-0.479882</td>\n",
              "      <td>-0.375551</td>\n",
              "      <td>0.518328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8604</th>\n",
              "      <td>1.400608</td>\n",
              "      <td>-1.399276</td>\n",
              "      <td>-0.323496</td>\n",
              "      <td>-0.381304</td>\n",
              "      <td>-0.119149</td>\n",
              "      <td>-0.025215</td>\n",
              "      <td>1.060573</td>\n",
              "      <td>2.564968</td>\n",
              "      <td>1.845607</td>\n",
              "      <td>-1.273684</td>\n",
              "      <td>0.181196</td>\n",
              "      <td>-0.925014</td>\n",
              "      <td>9.581747</td>\n",
              "      <td>-0.479882</td>\n",
              "      <td>-0.375551</td>\n",
              "      <td>0.518328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2988</th>\n",
              "      <td>0.144049</td>\n",
              "      <td>-0.157407</td>\n",
              "      <td>1.274123</td>\n",
              "      <td>0.953334</td>\n",
              "      <td>-0.119149</td>\n",
              "      <td>3.202795</td>\n",
              "      <td>-0.942781</td>\n",
              "      <td>-0.389825</td>\n",
              "      <td>-0.598686</td>\n",
              "      <td>-1.392711</td>\n",
              "      <td>-1.069836</td>\n",
              "      <td>1.285282</td>\n",
              "      <td>0.893161</td>\n",
              "      <td>1.778920</td>\n",
              "      <td>0.083679</td>\n",
              "      <td>-0.485173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099</th>\n",
              "      <td>-1.028739</td>\n",
              "      <td>1.705397</td>\n",
              "      <td>1.274123</td>\n",
              "      <td>-1.715942</td>\n",
              "      <td>-0.119149</td>\n",
              "      <td>-0.308172</td>\n",
              "      <td>-0.942781</td>\n",
              "      <td>-0.389825</td>\n",
              "      <td>-0.598686</td>\n",
              "      <td>1.582977</td>\n",
              "      <td>-0.444320</td>\n",
              "      <td>1.227722</td>\n",
              "      <td>-0.554937</td>\n",
              "      <td>-0.479882</td>\n",
              "      <td>-0.375551</td>\n",
              "      <td>0.518328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2514</th>\n",
              "      <td>-1.531363</td>\n",
              "      <td>1.084462</td>\n",
              "      <td>1.274123</td>\n",
              "      <td>-0.381304</td>\n",
              "      <td>-0.119149</td>\n",
              "      <td>-0.345013</td>\n",
              "      <td>-0.942781</td>\n",
              "      <td>-0.389825</td>\n",
              "      <td>-0.598686</td>\n",
              "      <td>-0.321464</td>\n",
              "      <td>-1.382594</td>\n",
              "      <td>0.349935</td>\n",
              "      <td>-0.192912</td>\n",
              "      <td>-0.479882</td>\n",
              "      <td>-0.375551</td>\n",
              "      <td>0.518328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6637</th>\n",
              "      <td>-0.191033</td>\n",
              "      <td>-0.157407</td>\n",
              "      <td>-0.323496</td>\n",
              "      <td>0.953334</td>\n",
              "      <td>-0.119149</td>\n",
              "      <td>-0.478442</td>\n",
              "      <td>1.060573</td>\n",
              "      <td>-0.389825</td>\n",
              "      <td>-0.598686</td>\n",
              "      <td>-0.559519</td>\n",
              "      <td>0.806711</td>\n",
              "      <td>-0.755213</td>\n",
              "      <td>-0.554937</td>\n",
              "      <td>-0.479882</td>\n",
              "      <td>-0.375551</td>\n",
              "      <td>0.518328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2575</th>\n",
              "      <td>1.568149</td>\n",
              "      <td>-1.399276</td>\n",
              "      <td>-0.323496</td>\n",
              "      <td>-0.381304</td>\n",
              "      <td>-0.119149</td>\n",
              "      <td>-0.445627</td>\n",
              "      <td>-0.942781</td>\n",
              "      <td>-0.389825</td>\n",
              "      <td>-0.598686</td>\n",
              "      <td>0.630757</td>\n",
              "      <td>-1.382594</td>\n",
              "      <td>-0.455902</td>\n",
              "      <td>0.169112</td>\n",
              "      <td>0.375303</td>\n",
              "      <td>0.083679</td>\n",
              "      <td>-0.485173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7336</th>\n",
              "      <td>-0.107263</td>\n",
              "      <td>-1.399276</td>\n",
              "      <td>-1.921114</td>\n",
              "      <td>-0.381304</td>\n",
              "      <td>-0.119149</td>\n",
              "      <td>-0.393617</td>\n",
              "      <td>1.060573</td>\n",
              "      <td>2.564968</td>\n",
              "      <td>-0.598686</td>\n",
              "      <td>1.106867</td>\n",
              "      <td>-0.131562</td>\n",
              "      <td>-0.925014</td>\n",
              "      <td>0.531137</td>\n",
              "      <td>-0.479882</td>\n",
              "      <td>-0.375551</td>\n",
              "      <td>0.518328</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8929 rows Ã— 16 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1f5db60-0930-4b33-9ddf-871989145ca0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d1f5db60-0930-4b33-9ddf-871989145ca0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d1f5db60-0930-4b33-9ddf-871989145ca0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-600e39b6-9ab4-430c-90ad-ed90eb77fac4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-600e39b6-9ab4-430c-90ad-ed90eb77fac4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-600e39b6-9ab4-430c-90ad-ed90eb77fac4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bfpWX2zWOfE",
        "outputId": "d6dc52c2-bfc2-4b88-f4af-6f49d236f6ba"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10713    0\n",
              "8431     0\n",
              "9060     0\n",
              "8604     0\n",
              "2988     1\n",
              "        ..\n",
              "1099     1\n",
              "2514     1\n",
              "6637     0\n",
              "2575     1\n",
              "7336     0\n",
              "Name: deposit, Length: 8929, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TKanGMZ0WOaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "69Rc9__AWOWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using ANN"
      ],
      "metadata": {
        "id": "tWY6d4ihWOSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# using ANN"
      ],
      "metadata": {
        "id": "DFGzieyh-5di"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "from numpy import asarray\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "GGLOHpQD_SgN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(20, activation='relu', input_shape = (16,)))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "fwLpTcvc_I0P"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_1WRfd5ChUJ",
        "outputId": "79848ece-8903-4f86-b422-7b551b3dd8d5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_18 (Dense)            (None, 20)                340       \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 20)                420       \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 781 (3.05 KB)\n",
            "Trainable params: 781 (3.05 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the keras model\n",
        "model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "LrOvki-pCj7w"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the keras model on the dataset\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=500, batch_size=50, validation_data = (X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LfHi_E6BQhT",
        "outputId": "7a2774c5-b70f-4064-bd68-a272ceefc58f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "179/179 [==============================] - 2s 5ms/step - loss: 0.6220 - accuracy: 0.6497 - val_loss: 0.5165 - val_accuracy: 0.7595\n",
            "Epoch 2/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.4817 - accuracy: 0.7862 - val_loss: 0.4493 - val_accuracy: 0.8007\n",
            "Epoch 3/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.4457 - accuracy: 0.8027 - val_loss: 0.4320 - val_accuracy: 0.8047\n",
            "Epoch 4/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.4314 - accuracy: 0.8094 - val_loss: 0.4243 - val_accuracy: 0.8101\n",
            "Epoch 5/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.4226 - accuracy: 0.8114 - val_loss: 0.4208 - val_accuracy: 0.8110\n",
            "Epoch 6/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.4172 - accuracy: 0.8131 - val_loss: 0.4170 - val_accuracy: 0.8106\n",
            "Epoch 7/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.4131 - accuracy: 0.8155 - val_loss: 0.4165 - val_accuracy: 0.8146\n",
            "Epoch 8/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.4106 - accuracy: 0.8160 - val_loss: 0.4163 - val_accuracy: 0.8124\n",
            "Epoch 9/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.4079 - accuracy: 0.8164 - val_loss: 0.4121 - val_accuracy: 0.8119\n",
            "Epoch 10/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.4059 - accuracy: 0.8160 - val_loss: 0.4119 - val_accuracy: 0.8115\n",
            "Epoch 11/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.4045 - accuracy: 0.8161 - val_loss: 0.4120 - val_accuracy: 0.8101\n",
            "Epoch 12/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.4016 - accuracy: 0.8206 - val_loss: 0.4120 - val_accuracy: 0.8128\n",
            "Epoch 13/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.4006 - accuracy: 0.8197 - val_loss: 0.4120 - val_accuracy: 0.8146\n",
            "Epoch 14/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3994 - accuracy: 0.8204 - val_loss: 0.4099 - val_accuracy: 0.8142\n",
            "Epoch 15/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3973 - accuracy: 0.8198 - val_loss: 0.4099 - val_accuracy: 0.8155\n",
            "Epoch 16/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3970 - accuracy: 0.8211 - val_loss: 0.4097 - val_accuracy: 0.8137\n",
            "Epoch 17/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3953 - accuracy: 0.8197 - val_loss: 0.4114 - val_accuracy: 0.8177\n",
            "Epoch 18/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3941 - accuracy: 0.8215 - val_loss: 0.4096 - val_accuracy: 0.8173\n",
            "Epoch 19/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3930 - accuracy: 0.8239 - val_loss: 0.4103 - val_accuracy: 0.8195\n",
            "Epoch 20/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3918 - accuracy: 0.8256 - val_loss: 0.4086 - val_accuracy: 0.8173\n",
            "Epoch 21/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3907 - accuracy: 0.8243 - val_loss: 0.4056 - val_accuracy: 0.8204\n",
            "Epoch 22/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3899 - accuracy: 0.8235 - val_loss: 0.4081 - val_accuracy: 0.8142\n",
            "Epoch 23/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3897 - accuracy: 0.8263 - val_loss: 0.4090 - val_accuracy: 0.8195\n",
            "Epoch 24/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3887 - accuracy: 0.8258 - val_loss: 0.4078 - val_accuracy: 0.8168\n",
            "Epoch 25/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3872 - accuracy: 0.8255 - val_loss: 0.4085 - val_accuracy: 0.8195\n",
            "Epoch 26/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3865 - accuracy: 0.8247 - val_loss: 0.4048 - val_accuracy: 0.8191\n",
            "Epoch 27/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3859 - accuracy: 0.8256 - val_loss: 0.4065 - val_accuracy: 0.8209\n",
            "Epoch 28/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3845 - accuracy: 0.8271 - val_loss: 0.4062 - val_accuracy: 0.8186\n",
            "Epoch 29/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3832 - accuracy: 0.8279 - val_loss: 0.4069 - val_accuracy: 0.8236\n",
            "Epoch 30/500\n",
            "179/179 [==============================] - 2s 9ms/step - loss: 0.3831 - accuracy: 0.8269 - val_loss: 0.4062 - val_accuracy: 0.8204\n",
            "Epoch 31/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3823 - accuracy: 0.8269 - val_loss: 0.4064 - val_accuracy: 0.8182\n",
            "Epoch 32/500\n",
            "179/179 [==============================] - 1s 7ms/step - loss: 0.3825 - accuracy: 0.8280 - val_loss: 0.4048 - val_accuracy: 0.8209\n",
            "Epoch 33/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3815 - accuracy: 0.8279 - val_loss: 0.4058 - val_accuracy: 0.8209\n",
            "Epoch 34/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3796 - accuracy: 0.8303 - val_loss: 0.4081 - val_accuracy: 0.8164\n",
            "Epoch 35/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3807 - accuracy: 0.8281 - val_loss: 0.4085 - val_accuracy: 0.8253\n",
            "Epoch 36/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3795 - accuracy: 0.8295 - val_loss: 0.4076 - val_accuracy: 0.8218\n",
            "Epoch 37/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3786 - accuracy: 0.8295 - val_loss: 0.4101 - val_accuracy: 0.8213\n",
            "Epoch 38/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3781 - accuracy: 0.8293 - val_loss: 0.4066 - val_accuracy: 0.8231\n",
            "Epoch 39/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3764 - accuracy: 0.8325 - val_loss: 0.4079 - val_accuracy: 0.8173\n",
            "Epoch 40/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3765 - accuracy: 0.8298 - val_loss: 0.4051 - val_accuracy: 0.8218\n",
            "Epoch 41/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3761 - accuracy: 0.8291 - val_loss: 0.4063 - val_accuracy: 0.8200\n",
            "Epoch 42/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3751 - accuracy: 0.8298 - val_loss: 0.4111 - val_accuracy: 0.8204\n",
            "Epoch 43/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3750 - accuracy: 0.8293 - val_loss: 0.4070 - val_accuracy: 0.8249\n",
            "Epoch 44/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3749 - accuracy: 0.8322 - val_loss: 0.4095 - val_accuracy: 0.8200\n",
            "Epoch 45/500\n",
            "179/179 [==============================] - 1s 7ms/step - loss: 0.3747 - accuracy: 0.8310 - val_loss: 0.4110 - val_accuracy: 0.8204\n",
            "Epoch 46/500\n",
            "179/179 [==============================] - 1s 8ms/step - loss: 0.3733 - accuracy: 0.8309 - val_loss: 0.4090 - val_accuracy: 0.8240\n",
            "Epoch 47/500\n",
            "179/179 [==============================] - 3s 14ms/step - loss: 0.3723 - accuracy: 0.8306 - val_loss: 0.4069 - val_accuracy: 0.8200\n",
            "Epoch 48/500\n",
            "179/179 [==============================] - 2s 12ms/step - loss: 0.3720 - accuracy: 0.8342 - val_loss: 0.4095 - val_accuracy: 0.8200\n",
            "Epoch 49/500\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 0.3721 - accuracy: 0.8316 - val_loss: 0.4082 - val_accuracy: 0.8227\n",
            "Epoch 50/500\n",
            "179/179 [==============================] - 1s 7ms/step - loss: 0.3710 - accuracy: 0.8325 - val_loss: 0.4118 - val_accuracy: 0.8218\n",
            "Epoch 51/500\n",
            "179/179 [==============================] - 1s 7ms/step - loss: 0.3703 - accuracy: 0.8321 - val_loss: 0.4113 - val_accuracy: 0.8227\n",
            "Epoch 52/500\n",
            "179/179 [==============================] - 2s 9ms/step - loss: 0.3701 - accuracy: 0.8332 - val_loss: 0.4112 - val_accuracy: 0.8204\n",
            "Epoch 53/500\n",
            "179/179 [==============================] - 1s 7ms/step - loss: 0.3692 - accuracy: 0.8351 - val_loss: 0.4096 - val_accuracy: 0.8218\n",
            "Epoch 54/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3690 - accuracy: 0.8350 - val_loss: 0.4093 - val_accuracy: 0.8182\n",
            "Epoch 55/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3684 - accuracy: 0.8350 - val_loss: 0.4109 - val_accuracy: 0.8182\n",
            "Epoch 56/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3674 - accuracy: 0.8348 - val_loss: 0.4102 - val_accuracy: 0.8227\n",
            "Epoch 57/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3677 - accuracy: 0.8348 - val_loss: 0.4121 - val_accuracy: 0.8195\n",
            "Epoch 58/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3666 - accuracy: 0.8356 - val_loss: 0.4089 - val_accuracy: 0.8195\n",
            "Epoch 59/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3667 - accuracy: 0.8362 - val_loss: 0.4108 - val_accuracy: 0.8236\n",
            "Epoch 60/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3670 - accuracy: 0.8364 - val_loss: 0.4117 - val_accuracy: 0.8209\n",
            "Epoch 61/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3651 - accuracy: 0.8351 - val_loss: 0.4103 - val_accuracy: 0.8267\n",
            "Epoch 62/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3650 - accuracy: 0.8363 - val_loss: 0.4119 - val_accuracy: 0.8249\n",
            "Epoch 63/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3654 - accuracy: 0.8368 - val_loss: 0.4122 - val_accuracy: 0.8240\n",
            "Epoch 64/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3641 - accuracy: 0.8396 - val_loss: 0.4156 - val_accuracy: 0.8222\n",
            "Epoch 65/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3640 - accuracy: 0.8381 - val_loss: 0.4123 - val_accuracy: 0.8231\n",
            "Epoch 66/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3638 - accuracy: 0.8375 - val_loss: 0.4132 - val_accuracy: 0.8186\n",
            "Epoch 67/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3630 - accuracy: 0.8395 - val_loss: 0.4127 - val_accuracy: 0.8222\n",
            "Epoch 68/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3629 - accuracy: 0.8375 - val_loss: 0.4133 - val_accuracy: 0.8227\n",
            "Epoch 69/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3624 - accuracy: 0.8375 - val_loss: 0.4135 - val_accuracy: 0.8222\n",
            "Epoch 70/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3623 - accuracy: 0.8387 - val_loss: 0.4171 - val_accuracy: 0.8204\n",
            "Epoch 71/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3619 - accuracy: 0.8383 - val_loss: 0.4145 - val_accuracy: 0.8213\n",
            "Epoch 72/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3616 - accuracy: 0.8392 - val_loss: 0.4154 - val_accuracy: 0.8222\n",
            "Epoch 73/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3619 - accuracy: 0.8370 - val_loss: 0.4126 - val_accuracy: 0.8209\n",
            "Epoch 74/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3609 - accuracy: 0.8397 - val_loss: 0.4140 - val_accuracy: 0.8236\n",
            "Epoch 75/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3597 - accuracy: 0.8395 - val_loss: 0.4170 - val_accuracy: 0.8191\n",
            "Epoch 76/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3601 - accuracy: 0.8372 - val_loss: 0.4157 - val_accuracy: 0.8204\n",
            "Epoch 77/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3598 - accuracy: 0.8402 - val_loss: 0.4161 - val_accuracy: 0.8209\n",
            "Epoch 78/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3586 - accuracy: 0.8411 - val_loss: 0.4169 - val_accuracy: 0.8200\n",
            "Epoch 79/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3599 - accuracy: 0.8416 - val_loss: 0.4155 - val_accuracy: 0.8218\n",
            "Epoch 80/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3577 - accuracy: 0.8409 - val_loss: 0.4155 - val_accuracy: 0.8258\n",
            "Epoch 81/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3585 - accuracy: 0.8414 - val_loss: 0.4180 - val_accuracy: 0.8200\n",
            "Epoch 82/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3584 - accuracy: 0.8431 - val_loss: 0.4176 - val_accuracy: 0.8195\n",
            "Epoch 83/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3573 - accuracy: 0.8425 - val_loss: 0.4196 - val_accuracy: 0.8182\n",
            "Epoch 84/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3570 - accuracy: 0.8415 - val_loss: 0.4179 - val_accuracy: 0.8213\n",
            "Epoch 85/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3566 - accuracy: 0.8420 - val_loss: 0.4202 - val_accuracy: 0.8213\n",
            "Epoch 86/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3566 - accuracy: 0.8428 - val_loss: 0.4176 - val_accuracy: 0.8204\n",
            "Epoch 87/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3568 - accuracy: 0.8439 - val_loss: 0.4170 - val_accuracy: 0.8204\n",
            "Epoch 88/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3564 - accuracy: 0.8421 - val_loss: 0.4229 - val_accuracy: 0.8137\n",
            "Epoch 89/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3566 - accuracy: 0.8411 - val_loss: 0.4194 - val_accuracy: 0.8204\n",
            "Epoch 90/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3562 - accuracy: 0.8419 - val_loss: 0.4183 - val_accuracy: 0.8195\n",
            "Epoch 91/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3553 - accuracy: 0.8434 - val_loss: 0.4186 - val_accuracy: 0.8209\n",
            "Epoch 92/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3548 - accuracy: 0.8416 - val_loss: 0.4206 - val_accuracy: 0.8155\n",
            "Epoch 93/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3553 - accuracy: 0.8413 - val_loss: 0.4160 - val_accuracy: 0.8182\n",
            "Epoch 94/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3549 - accuracy: 0.8444 - val_loss: 0.4201 - val_accuracy: 0.8245\n",
            "Epoch 95/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3543 - accuracy: 0.8442 - val_loss: 0.4200 - val_accuracy: 0.8240\n",
            "Epoch 96/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3535 - accuracy: 0.8435 - val_loss: 0.4201 - val_accuracy: 0.8213\n",
            "Epoch 97/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3533 - accuracy: 0.8439 - val_loss: 0.4238 - val_accuracy: 0.8164\n",
            "Epoch 98/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3537 - accuracy: 0.8449 - val_loss: 0.4214 - val_accuracy: 0.8186\n",
            "Epoch 99/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3540 - accuracy: 0.8440 - val_loss: 0.4193 - val_accuracy: 0.8231\n",
            "Epoch 100/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3530 - accuracy: 0.8448 - val_loss: 0.4191 - val_accuracy: 0.8213\n",
            "Epoch 101/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3521 - accuracy: 0.8423 - val_loss: 0.4227 - val_accuracy: 0.8204\n",
            "Epoch 102/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3531 - accuracy: 0.8438 - val_loss: 0.4236 - val_accuracy: 0.8191\n",
            "Epoch 103/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3515 - accuracy: 0.8450 - val_loss: 0.4205 - val_accuracy: 0.8195\n",
            "Epoch 104/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3512 - accuracy: 0.8456 - val_loss: 0.4256 - val_accuracy: 0.8159\n",
            "Epoch 105/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3516 - accuracy: 0.8457 - val_loss: 0.4231 - val_accuracy: 0.8177\n",
            "Epoch 106/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3514 - accuracy: 0.8484 - val_loss: 0.4234 - val_accuracy: 0.8191\n",
            "Epoch 107/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3512 - accuracy: 0.8465 - val_loss: 0.4239 - val_accuracy: 0.8173\n",
            "Epoch 108/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3510 - accuracy: 0.8467 - val_loss: 0.4235 - val_accuracy: 0.8168\n",
            "Epoch 109/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3497 - accuracy: 0.8474 - val_loss: 0.4231 - val_accuracy: 0.8213\n",
            "Epoch 110/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3507 - accuracy: 0.8465 - val_loss: 0.4230 - val_accuracy: 0.8191\n",
            "Epoch 111/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3506 - accuracy: 0.8475 - val_loss: 0.4249 - val_accuracy: 0.8146\n",
            "Epoch 112/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3500 - accuracy: 0.8482 - val_loss: 0.4242 - val_accuracy: 0.8191\n",
            "Epoch 113/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3497 - accuracy: 0.8485 - val_loss: 0.4257 - val_accuracy: 0.8200\n",
            "Epoch 114/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3498 - accuracy: 0.8475 - val_loss: 0.4266 - val_accuracy: 0.8168\n",
            "Epoch 115/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3492 - accuracy: 0.8490 - val_loss: 0.4242 - val_accuracy: 0.8227\n",
            "Epoch 116/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3492 - accuracy: 0.8497 - val_loss: 0.4243 - val_accuracy: 0.8168\n",
            "Epoch 117/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3492 - accuracy: 0.8486 - val_loss: 0.4251 - val_accuracy: 0.8159\n",
            "Epoch 118/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3499 - accuracy: 0.8493 - val_loss: 0.4259 - val_accuracy: 0.8142\n",
            "Epoch 119/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3484 - accuracy: 0.8472 - val_loss: 0.4288 - val_accuracy: 0.8186\n",
            "Epoch 120/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3480 - accuracy: 0.8494 - val_loss: 0.4342 - val_accuracy: 0.8110\n",
            "Epoch 121/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3482 - accuracy: 0.8478 - val_loss: 0.4270 - val_accuracy: 0.8150\n",
            "Epoch 122/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3480 - accuracy: 0.8486 - val_loss: 0.4252 - val_accuracy: 0.8142\n",
            "Epoch 123/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3482 - accuracy: 0.8476 - val_loss: 0.4279 - val_accuracy: 0.8177\n",
            "Epoch 124/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3473 - accuracy: 0.8488 - val_loss: 0.4323 - val_accuracy: 0.8164\n",
            "Epoch 125/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3478 - accuracy: 0.8468 - val_loss: 0.4261 - val_accuracy: 0.8115\n",
            "Epoch 126/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3478 - accuracy: 0.8491 - val_loss: 0.4264 - val_accuracy: 0.8155\n",
            "Epoch 127/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3479 - accuracy: 0.8499 - val_loss: 0.4271 - val_accuracy: 0.8200\n",
            "Epoch 128/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3467 - accuracy: 0.8495 - val_loss: 0.4267 - val_accuracy: 0.8155\n",
            "Epoch 129/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3472 - accuracy: 0.8495 - val_loss: 0.4279 - val_accuracy: 0.8191\n",
            "Epoch 130/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3468 - accuracy: 0.8490 - val_loss: 0.4275 - val_accuracy: 0.8209\n",
            "Epoch 131/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3467 - accuracy: 0.8497 - val_loss: 0.4310 - val_accuracy: 0.8155\n",
            "Epoch 132/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3458 - accuracy: 0.8498 - val_loss: 0.4282 - val_accuracy: 0.8213\n",
            "Epoch 133/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3457 - accuracy: 0.8499 - val_loss: 0.4278 - val_accuracy: 0.8168\n",
            "Epoch 134/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3457 - accuracy: 0.8495 - val_loss: 0.4271 - val_accuracy: 0.8146\n",
            "Epoch 135/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3450 - accuracy: 0.8512 - val_loss: 0.4279 - val_accuracy: 0.8186\n",
            "Epoch 136/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3459 - accuracy: 0.8497 - val_loss: 0.4284 - val_accuracy: 0.8155\n",
            "Epoch 137/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3445 - accuracy: 0.8478 - val_loss: 0.4285 - val_accuracy: 0.8150\n",
            "Epoch 138/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3437 - accuracy: 0.8515 - val_loss: 0.4316 - val_accuracy: 0.8173\n",
            "Epoch 139/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3450 - accuracy: 0.8487 - val_loss: 0.4302 - val_accuracy: 0.8173\n",
            "Epoch 140/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3439 - accuracy: 0.8517 - val_loss: 0.4317 - val_accuracy: 0.8150\n",
            "Epoch 141/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3440 - accuracy: 0.8514 - val_loss: 0.4329 - val_accuracy: 0.8155\n",
            "Epoch 142/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3441 - accuracy: 0.8510 - val_loss: 0.4277 - val_accuracy: 0.8168\n",
            "Epoch 143/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3438 - accuracy: 0.8514 - val_loss: 0.4328 - val_accuracy: 0.8164\n",
            "Epoch 144/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3439 - accuracy: 0.8519 - val_loss: 0.4296 - val_accuracy: 0.8182\n",
            "Epoch 145/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3438 - accuracy: 0.8510 - val_loss: 0.4292 - val_accuracy: 0.8191\n",
            "Epoch 146/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3421 - accuracy: 0.8532 - val_loss: 0.4332 - val_accuracy: 0.8159\n",
            "Epoch 147/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3427 - accuracy: 0.8527 - val_loss: 0.4350 - val_accuracy: 0.8177\n",
            "Epoch 148/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3420 - accuracy: 0.8532 - val_loss: 0.4325 - val_accuracy: 0.8186\n",
            "Epoch 149/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3417 - accuracy: 0.8507 - val_loss: 0.4344 - val_accuracy: 0.8137\n",
            "Epoch 150/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3417 - accuracy: 0.8514 - val_loss: 0.4296 - val_accuracy: 0.8191\n",
            "Epoch 151/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3414 - accuracy: 0.8530 - val_loss: 0.4314 - val_accuracy: 0.8222\n",
            "Epoch 152/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3416 - accuracy: 0.8497 - val_loss: 0.4331 - val_accuracy: 0.8191\n",
            "Epoch 153/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3413 - accuracy: 0.8527 - val_loss: 0.4306 - val_accuracy: 0.8182\n",
            "Epoch 154/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3413 - accuracy: 0.8513 - val_loss: 0.4325 - val_accuracy: 0.8186\n",
            "Epoch 155/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3409 - accuracy: 0.8528 - val_loss: 0.4324 - val_accuracy: 0.8155\n",
            "Epoch 156/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3399 - accuracy: 0.8530 - val_loss: 0.4333 - val_accuracy: 0.8177\n",
            "Epoch 157/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3401 - accuracy: 0.8530 - val_loss: 0.4336 - val_accuracy: 0.8173\n",
            "Epoch 158/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3397 - accuracy: 0.8505 - val_loss: 0.4315 - val_accuracy: 0.8164\n",
            "Epoch 159/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3398 - accuracy: 0.8549 - val_loss: 0.4314 - val_accuracy: 0.8191\n",
            "Epoch 160/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3386 - accuracy: 0.8510 - val_loss: 0.4342 - val_accuracy: 0.8146\n",
            "Epoch 161/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3388 - accuracy: 0.8536 - val_loss: 0.4331 - val_accuracy: 0.8137\n",
            "Epoch 162/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3397 - accuracy: 0.8528 - val_loss: 0.4294 - val_accuracy: 0.8159\n",
            "Epoch 163/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3387 - accuracy: 0.8537 - val_loss: 0.4301 - val_accuracy: 0.8155\n",
            "Epoch 164/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3394 - accuracy: 0.8542 - val_loss: 0.4295 - val_accuracy: 0.8173\n",
            "Epoch 165/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3392 - accuracy: 0.8549 - val_loss: 0.4296 - val_accuracy: 0.8200\n",
            "Epoch 166/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3378 - accuracy: 0.8527 - val_loss: 0.4325 - val_accuracy: 0.8182\n",
            "Epoch 167/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3382 - accuracy: 0.8533 - val_loss: 0.4335 - val_accuracy: 0.8155\n",
            "Epoch 168/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3381 - accuracy: 0.8536 - val_loss: 0.4327 - val_accuracy: 0.8173\n",
            "Epoch 169/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3363 - accuracy: 0.8559 - val_loss: 0.4311 - val_accuracy: 0.8155\n",
            "Epoch 170/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3374 - accuracy: 0.8530 - val_loss: 0.4308 - val_accuracy: 0.8164\n",
            "Epoch 171/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3368 - accuracy: 0.8543 - val_loss: 0.4334 - val_accuracy: 0.8195\n",
            "Epoch 172/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3374 - accuracy: 0.8563 - val_loss: 0.4318 - val_accuracy: 0.8186\n",
            "Epoch 173/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3361 - accuracy: 0.8566 - val_loss: 0.4321 - val_accuracy: 0.8146\n",
            "Epoch 174/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3362 - accuracy: 0.8540 - val_loss: 0.4323 - val_accuracy: 0.8159\n",
            "Epoch 175/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3348 - accuracy: 0.8562 - val_loss: 0.4368 - val_accuracy: 0.8146\n",
            "Epoch 176/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3356 - accuracy: 0.8545 - val_loss: 0.4339 - val_accuracy: 0.8124\n",
            "Epoch 177/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3350 - accuracy: 0.8569 - val_loss: 0.4324 - val_accuracy: 0.8209\n",
            "Epoch 178/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3349 - accuracy: 0.8563 - val_loss: 0.4277 - val_accuracy: 0.8168\n",
            "Epoch 179/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3347 - accuracy: 0.8564 - val_loss: 0.4377 - val_accuracy: 0.8124\n",
            "Epoch 180/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3357 - accuracy: 0.8563 - val_loss: 0.4354 - val_accuracy: 0.8124\n",
            "Epoch 181/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3341 - accuracy: 0.8572 - val_loss: 0.4293 - val_accuracy: 0.8146\n",
            "Epoch 182/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3351 - accuracy: 0.8534 - val_loss: 0.4334 - val_accuracy: 0.8168\n",
            "Epoch 183/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3340 - accuracy: 0.8552 - val_loss: 0.4332 - val_accuracy: 0.8182\n",
            "Epoch 184/500\n",
            "179/179 [==============================] - 2s 10ms/step - loss: 0.3331 - accuracy: 0.8562 - val_loss: 0.4324 - val_accuracy: 0.8182\n",
            "Epoch 185/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3331 - accuracy: 0.8574 - val_loss: 0.4345 - val_accuracy: 0.8177\n",
            "Epoch 186/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3338 - accuracy: 0.8568 - val_loss: 0.4357 - val_accuracy: 0.8150\n",
            "Epoch 187/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3328 - accuracy: 0.8550 - val_loss: 0.4296 - val_accuracy: 0.8133\n",
            "Epoch 188/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3331 - accuracy: 0.8575 - val_loss: 0.4345 - val_accuracy: 0.8186\n",
            "Epoch 189/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3322 - accuracy: 0.8592 - val_loss: 0.4302 - val_accuracy: 0.8128\n",
            "Epoch 190/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3334 - accuracy: 0.8559 - val_loss: 0.4313 - val_accuracy: 0.8137\n",
            "Epoch 191/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3326 - accuracy: 0.8579 - val_loss: 0.4353 - val_accuracy: 0.8186\n",
            "Epoch 192/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3326 - accuracy: 0.8575 - val_loss: 0.4341 - val_accuracy: 0.8155\n",
            "Epoch 193/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3311 - accuracy: 0.8574 - val_loss: 0.4323 - val_accuracy: 0.8150\n",
            "Epoch 194/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3314 - accuracy: 0.8559 - val_loss: 0.4292 - val_accuracy: 0.8213\n",
            "Epoch 195/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3318 - accuracy: 0.8566 - val_loss: 0.4329 - val_accuracy: 0.8191\n",
            "Epoch 196/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3317 - accuracy: 0.8590 - val_loss: 0.4314 - val_accuracy: 0.8186\n",
            "Epoch 197/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3316 - accuracy: 0.8582 - val_loss: 0.4365 - val_accuracy: 0.8092\n",
            "Epoch 198/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3313 - accuracy: 0.8580 - val_loss: 0.4353 - val_accuracy: 0.8182\n",
            "Epoch 199/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3327 - accuracy: 0.8560 - val_loss: 0.4340 - val_accuracy: 0.8168\n",
            "Epoch 200/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3307 - accuracy: 0.8577 - val_loss: 0.4378 - val_accuracy: 0.8124\n",
            "Epoch 201/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3310 - accuracy: 0.8588 - val_loss: 0.4348 - val_accuracy: 0.8159\n",
            "Epoch 202/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3299 - accuracy: 0.8579 - val_loss: 0.4345 - val_accuracy: 0.8128\n",
            "Epoch 203/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3312 - accuracy: 0.8573 - val_loss: 0.4325 - val_accuracy: 0.8182\n",
            "Epoch 204/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3310 - accuracy: 0.8574 - val_loss: 0.4333 - val_accuracy: 0.8150\n",
            "Epoch 205/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3308 - accuracy: 0.8601 - val_loss: 0.4362 - val_accuracy: 0.8137\n",
            "Epoch 206/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3303 - accuracy: 0.8589 - val_loss: 0.4356 - val_accuracy: 0.8186\n",
            "Epoch 207/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3303 - accuracy: 0.8582 - val_loss: 0.4320 - val_accuracy: 0.8209\n",
            "Epoch 208/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3293 - accuracy: 0.8578 - val_loss: 0.4365 - val_accuracy: 0.8088\n",
            "Epoch 209/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3311 - accuracy: 0.8573 - val_loss: 0.4315 - val_accuracy: 0.8119\n",
            "Epoch 210/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3309 - accuracy: 0.8568 - val_loss: 0.4372 - val_accuracy: 0.8133\n",
            "Epoch 211/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3294 - accuracy: 0.8569 - val_loss: 0.4347 - val_accuracy: 0.8106\n",
            "Epoch 212/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3293 - accuracy: 0.8616 - val_loss: 0.4319 - val_accuracy: 0.8155\n",
            "Epoch 213/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3289 - accuracy: 0.8600 - val_loss: 0.4351 - val_accuracy: 0.8137\n",
            "Epoch 214/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3293 - accuracy: 0.8572 - val_loss: 0.4360 - val_accuracy: 0.8155\n",
            "Epoch 215/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3295 - accuracy: 0.8580 - val_loss: 0.4345 - val_accuracy: 0.8142\n",
            "Epoch 216/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3283 - accuracy: 0.8574 - val_loss: 0.4335 - val_accuracy: 0.8110\n",
            "Epoch 217/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3285 - accuracy: 0.8593 - val_loss: 0.4347 - val_accuracy: 0.8159\n",
            "Epoch 218/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3285 - accuracy: 0.8627 - val_loss: 0.4402 - val_accuracy: 0.8119\n",
            "Epoch 219/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3285 - accuracy: 0.8602 - val_loss: 0.4358 - val_accuracy: 0.8119\n",
            "Epoch 220/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3288 - accuracy: 0.8596 - val_loss: 0.4358 - val_accuracy: 0.8110\n",
            "Epoch 221/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3276 - accuracy: 0.8608 - val_loss: 0.4388 - val_accuracy: 0.8155\n",
            "Epoch 222/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3286 - accuracy: 0.8581 - val_loss: 0.4315 - val_accuracy: 0.8128\n",
            "Epoch 223/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3268 - accuracy: 0.8616 - val_loss: 0.4376 - val_accuracy: 0.8200\n",
            "Epoch 224/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3288 - accuracy: 0.8610 - val_loss: 0.4380 - val_accuracy: 0.8173\n",
            "Epoch 225/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3269 - accuracy: 0.8609 - val_loss: 0.4401 - val_accuracy: 0.8150\n",
            "Epoch 226/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3278 - accuracy: 0.8584 - val_loss: 0.4371 - val_accuracy: 0.8159\n",
            "Epoch 227/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3273 - accuracy: 0.8614 - val_loss: 0.4369 - val_accuracy: 0.8186\n",
            "Epoch 228/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3266 - accuracy: 0.8610 - val_loss: 0.4339 - val_accuracy: 0.8186\n",
            "Epoch 229/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3264 - accuracy: 0.8611 - val_loss: 0.4444 - val_accuracy: 0.8128\n",
            "Epoch 230/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3272 - accuracy: 0.8587 - val_loss: 0.4359 - val_accuracy: 0.8182\n",
            "Epoch 231/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3264 - accuracy: 0.8584 - val_loss: 0.4384 - val_accuracy: 0.8155\n",
            "Epoch 232/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3270 - accuracy: 0.8609 - val_loss: 0.4398 - val_accuracy: 0.8164\n",
            "Epoch 233/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3259 - accuracy: 0.8596 - val_loss: 0.4368 - val_accuracy: 0.8150\n",
            "Epoch 234/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3276 - accuracy: 0.8609 - val_loss: 0.4339 - val_accuracy: 0.8200\n",
            "Epoch 235/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3267 - accuracy: 0.8610 - val_loss: 0.4410 - val_accuracy: 0.8191\n",
            "Epoch 236/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3273 - accuracy: 0.8590 - val_loss: 0.4376 - val_accuracy: 0.8168\n",
            "Epoch 237/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3260 - accuracy: 0.8598 - val_loss: 0.4355 - val_accuracy: 0.8182\n",
            "Epoch 238/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3257 - accuracy: 0.8617 - val_loss: 0.4494 - val_accuracy: 0.8133\n",
            "Epoch 239/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3262 - accuracy: 0.8618 - val_loss: 0.4424 - val_accuracy: 0.8128\n",
            "Epoch 240/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3283 - accuracy: 0.8588 - val_loss: 0.4370 - val_accuracy: 0.8186\n",
            "Epoch 241/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3254 - accuracy: 0.8616 - val_loss: 0.4363 - val_accuracy: 0.8213\n",
            "Epoch 242/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3245 - accuracy: 0.8638 - val_loss: 0.4408 - val_accuracy: 0.8177\n",
            "Epoch 243/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3258 - accuracy: 0.8607 - val_loss: 0.4387 - val_accuracy: 0.8177\n",
            "Epoch 244/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3258 - accuracy: 0.8611 - val_loss: 0.4381 - val_accuracy: 0.8168\n",
            "Epoch 245/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3250 - accuracy: 0.8617 - val_loss: 0.4378 - val_accuracy: 0.8177\n",
            "Epoch 246/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3259 - accuracy: 0.8624 - val_loss: 0.4365 - val_accuracy: 0.8186\n",
            "Epoch 247/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3254 - accuracy: 0.8610 - val_loss: 0.4405 - val_accuracy: 0.8164\n",
            "Epoch 248/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3254 - accuracy: 0.8598 - val_loss: 0.4441 - val_accuracy: 0.8124\n",
            "Epoch 249/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3242 - accuracy: 0.8617 - val_loss: 0.4386 - val_accuracy: 0.8173\n",
            "Epoch 250/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3249 - accuracy: 0.8611 - val_loss: 0.4407 - val_accuracy: 0.8200\n",
            "Epoch 251/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3240 - accuracy: 0.8615 - val_loss: 0.4360 - val_accuracy: 0.8173\n",
            "Epoch 252/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3252 - accuracy: 0.8642 - val_loss: 0.4387 - val_accuracy: 0.8150\n",
            "Epoch 253/500\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 0.3253 - accuracy: 0.8614 - val_loss: 0.4393 - val_accuracy: 0.8177\n",
            "Epoch 254/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3247 - accuracy: 0.8599 - val_loss: 0.4449 - val_accuracy: 0.8115\n",
            "Epoch 255/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3255 - accuracy: 0.8625 - val_loss: 0.4419 - val_accuracy: 0.8159\n",
            "Epoch 256/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3235 - accuracy: 0.8616 - val_loss: 0.4388 - val_accuracy: 0.8186\n",
            "Epoch 257/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3235 - accuracy: 0.8628 - val_loss: 0.4439 - val_accuracy: 0.8168\n",
            "Epoch 258/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3250 - accuracy: 0.8622 - val_loss: 0.4392 - val_accuracy: 0.8195\n",
            "Epoch 259/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3247 - accuracy: 0.8622 - val_loss: 0.4411 - val_accuracy: 0.8177\n",
            "Epoch 260/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3244 - accuracy: 0.8624 - val_loss: 0.4477 - val_accuracy: 0.8124\n",
            "Epoch 261/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3239 - accuracy: 0.8621 - val_loss: 0.4449 - val_accuracy: 0.8168\n",
            "Epoch 262/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3249 - accuracy: 0.8594 - val_loss: 0.4408 - val_accuracy: 0.8106\n",
            "Epoch 263/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3242 - accuracy: 0.8628 - val_loss: 0.4397 - val_accuracy: 0.8173\n",
            "Epoch 264/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3236 - accuracy: 0.8633 - val_loss: 0.4431 - val_accuracy: 0.8182\n",
            "Epoch 265/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3224 - accuracy: 0.8635 - val_loss: 0.4375 - val_accuracy: 0.8213\n",
            "Epoch 266/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3243 - accuracy: 0.8611 - val_loss: 0.4412 - val_accuracy: 0.8195\n",
            "Epoch 267/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3229 - accuracy: 0.8622 - val_loss: 0.4447 - val_accuracy: 0.8142\n",
            "Epoch 268/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3231 - accuracy: 0.8635 - val_loss: 0.4416 - val_accuracy: 0.8164\n",
            "Epoch 269/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3234 - accuracy: 0.8602 - val_loss: 0.4433 - val_accuracy: 0.8119\n",
            "Epoch 270/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3223 - accuracy: 0.8637 - val_loss: 0.4384 - val_accuracy: 0.8191\n",
            "Epoch 271/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3226 - accuracy: 0.8615 - val_loss: 0.4446 - val_accuracy: 0.8106\n",
            "Epoch 272/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3244 - accuracy: 0.8629 - val_loss: 0.4410 - val_accuracy: 0.8191\n",
            "Epoch 273/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3220 - accuracy: 0.8628 - val_loss: 0.4429 - val_accuracy: 0.8159\n",
            "Epoch 274/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3231 - accuracy: 0.8648 - val_loss: 0.4410 - val_accuracy: 0.8204\n",
            "Epoch 275/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3235 - accuracy: 0.8625 - val_loss: 0.4422 - val_accuracy: 0.8150\n",
            "Epoch 276/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3234 - accuracy: 0.8635 - val_loss: 0.4444 - val_accuracy: 0.8182\n",
            "Epoch 277/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3224 - accuracy: 0.8636 - val_loss: 0.4404 - val_accuracy: 0.8177\n",
            "Epoch 278/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3214 - accuracy: 0.8610 - val_loss: 0.4415 - val_accuracy: 0.8218\n",
            "Epoch 279/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3213 - accuracy: 0.8626 - val_loss: 0.4396 - val_accuracy: 0.8137\n",
            "Epoch 280/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3228 - accuracy: 0.8646 - val_loss: 0.4530 - val_accuracy: 0.8164\n",
            "Epoch 281/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3233 - accuracy: 0.8612 - val_loss: 0.4433 - val_accuracy: 0.8173\n",
            "Epoch 282/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3225 - accuracy: 0.8615 - val_loss: 0.4435 - val_accuracy: 0.8159\n",
            "Epoch 283/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3222 - accuracy: 0.8620 - val_loss: 0.4404 - val_accuracy: 0.8164\n",
            "Epoch 284/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3217 - accuracy: 0.8624 - val_loss: 0.4488 - val_accuracy: 0.8124\n",
            "Epoch 285/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3235 - accuracy: 0.8626 - val_loss: 0.4506 - val_accuracy: 0.8106\n",
            "Epoch 286/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3234 - accuracy: 0.8630 - val_loss: 0.4426 - val_accuracy: 0.8191\n",
            "Epoch 287/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3218 - accuracy: 0.8628 - val_loss: 0.4428 - val_accuracy: 0.8150\n",
            "Epoch 288/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3219 - accuracy: 0.8614 - val_loss: 0.4481 - val_accuracy: 0.8106\n",
            "Epoch 289/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3224 - accuracy: 0.8622 - val_loss: 0.4391 - val_accuracy: 0.8146\n",
            "Epoch 290/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3222 - accuracy: 0.8620 - val_loss: 0.4426 - val_accuracy: 0.8182\n",
            "Epoch 291/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3211 - accuracy: 0.8620 - val_loss: 0.4409 - val_accuracy: 0.8218\n",
            "Epoch 292/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3218 - accuracy: 0.8631 - val_loss: 0.4416 - val_accuracy: 0.8186\n",
            "Epoch 293/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3225 - accuracy: 0.8631 - val_loss: 0.4560 - val_accuracy: 0.8047\n",
            "Epoch 294/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3218 - accuracy: 0.8649 - val_loss: 0.4409 - val_accuracy: 0.8164\n",
            "Epoch 295/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3207 - accuracy: 0.8631 - val_loss: 0.4430 - val_accuracy: 0.8150\n",
            "Epoch 296/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3215 - accuracy: 0.8635 - val_loss: 0.4455 - val_accuracy: 0.8173\n",
            "Epoch 297/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3215 - accuracy: 0.8629 - val_loss: 0.4426 - val_accuracy: 0.8155\n",
            "Epoch 298/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3204 - accuracy: 0.8637 - val_loss: 0.4490 - val_accuracy: 0.8173\n",
            "Epoch 299/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3217 - accuracy: 0.8633 - val_loss: 0.4438 - val_accuracy: 0.8155\n",
            "Epoch 300/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3204 - accuracy: 0.8626 - val_loss: 0.4452 - val_accuracy: 0.8137\n",
            "Epoch 301/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3210 - accuracy: 0.8657 - val_loss: 0.4465 - val_accuracy: 0.8182\n",
            "Epoch 302/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3216 - accuracy: 0.8646 - val_loss: 0.4458 - val_accuracy: 0.8159\n",
            "Epoch 303/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3201 - accuracy: 0.8643 - val_loss: 0.4491 - val_accuracy: 0.8110\n",
            "Epoch 304/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3211 - accuracy: 0.8618 - val_loss: 0.4453 - val_accuracy: 0.8200\n",
            "Epoch 305/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3208 - accuracy: 0.8634 - val_loss: 0.4432 - val_accuracy: 0.8177\n",
            "Epoch 306/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3199 - accuracy: 0.8626 - val_loss: 0.4466 - val_accuracy: 0.8177\n",
            "Epoch 307/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3215 - accuracy: 0.8631 - val_loss: 0.4440 - val_accuracy: 0.8146\n",
            "Epoch 308/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3214 - accuracy: 0.8626 - val_loss: 0.4465 - val_accuracy: 0.8177\n",
            "Epoch 309/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3198 - accuracy: 0.8639 - val_loss: 0.4438 - val_accuracy: 0.8200\n",
            "Epoch 310/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3224 - accuracy: 0.8622 - val_loss: 0.4452 - val_accuracy: 0.8191\n",
            "Epoch 311/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3202 - accuracy: 0.8633 - val_loss: 0.4448 - val_accuracy: 0.8182\n",
            "Epoch 312/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3197 - accuracy: 0.8635 - val_loss: 0.4470 - val_accuracy: 0.8159\n",
            "Epoch 313/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3202 - accuracy: 0.8630 - val_loss: 0.4444 - val_accuracy: 0.8124\n",
            "Epoch 314/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3202 - accuracy: 0.8621 - val_loss: 0.4507 - val_accuracy: 0.8146\n",
            "Epoch 315/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3198 - accuracy: 0.8630 - val_loss: 0.4479 - val_accuracy: 0.8142\n",
            "Epoch 316/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3196 - accuracy: 0.8644 - val_loss: 0.4491 - val_accuracy: 0.8155\n",
            "Epoch 317/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3211 - accuracy: 0.8620 - val_loss: 0.4443 - val_accuracy: 0.8182\n",
            "Epoch 318/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3192 - accuracy: 0.8629 - val_loss: 0.4437 - val_accuracy: 0.8218\n",
            "Epoch 319/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3191 - accuracy: 0.8645 - val_loss: 0.4483 - val_accuracy: 0.8177\n",
            "Epoch 320/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3194 - accuracy: 0.8635 - val_loss: 0.4579 - val_accuracy: 0.8097\n",
            "Epoch 321/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3189 - accuracy: 0.8637 - val_loss: 0.4492 - val_accuracy: 0.8173\n",
            "Epoch 322/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3198 - accuracy: 0.8625 - val_loss: 0.4536 - val_accuracy: 0.8119\n",
            "Epoch 323/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3195 - accuracy: 0.8637 - val_loss: 0.4479 - val_accuracy: 0.8155\n",
            "Epoch 324/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3196 - accuracy: 0.8630 - val_loss: 0.4456 - val_accuracy: 0.8128\n",
            "Epoch 325/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3205 - accuracy: 0.8627 - val_loss: 0.4473 - val_accuracy: 0.8124\n",
            "Epoch 326/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3195 - accuracy: 0.8629 - val_loss: 0.4451 - val_accuracy: 0.8128\n",
            "Epoch 327/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3190 - accuracy: 0.8619 - val_loss: 0.4527 - val_accuracy: 0.8133\n",
            "Epoch 328/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3187 - accuracy: 0.8640 - val_loss: 0.4559 - val_accuracy: 0.8133\n",
            "Epoch 329/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3200 - accuracy: 0.8612 - val_loss: 0.4458 - val_accuracy: 0.8213\n",
            "Epoch 330/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3189 - accuracy: 0.8648 - val_loss: 0.4452 - val_accuracy: 0.8173\n",
            "Epoch 331/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3190 - accuracy: 0.8647 - val_loss: 0.4428 - val_accuracy: 0.8236\n",
            "Epoch 332/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3180 - accuracy: 0.8631 - val_loss: 0.4488 - val_accuracy: 0.8137\n",
            "Epoch 333/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3189 - accuracy: 0.8630 - val_loss: 0.4469 - val_accuracy: 0.8150\n",
            "Epoch 334/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3186 - accuracy: 0.8646 - val_loss: 0.4464 - val_accuracy: 0.8173\n",
            "Epoch 335/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3189 - accuracy: 0.8630 - val_loss: 0.4493 - val_accuracy: 0.8227\n",
            "Epoch 336/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3186 - accuracy: 0.8597 - val_loss: 0.4539 - val_accuracy: 0.8146\n",
            "Epoch 337/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3182 - accuracy: 0.8633 - val_loss: 0.4492 - val_accuracy: 0.8168\n",
            "Epoch 338/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3196 - accuracy: 0.8640 - val_loss: 0.4415 - val_accuracy: 0.8191\n",
            "Epoch 339/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3184 - accuracy: 0.8625 - val_loss: 0.4558 - val_accuracy: 0.8133\n",
            "Epoch 340/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3182 - accuracy: 0.8639 - val_loss: 0.4473 - val_accuracy: 0.8173\n",
            "Epoch 341/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3187 - accuracy: 0.8634 - val_loss: 0.4542 - val_accuracy: 0.8173\n",
            "Epoch 342/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3183 - accuracy: 0.8661 - val_loss: 0.4536 - val_accuracy: 0.8106\n",
            "Epoch 343/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3200 - accuracy: 0.8610 - val_loss: 0.4514 - val_accuracy: 0.8168\n",
            "Epoch 344/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3192 - accuracy: 0.8631 - val_loss: 0.4470 - val_accuracy: 0.8222\n",
            "Epoch 345/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3177 - accuracy: 0.8643 - val_loss: 0.4494 - val_accuracy: 0.8159\n",
            "Epoch 346/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3183 - accuracy: 0.8608 - val_loss: 0.4537 - val_accuracy: 0.8155\n",
            "Epoch 347/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3180 - accuracy: 0.8622 - val_loss: 0.4452 - val_accuracy: 0.8204\n",
            "Epoch 348/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3185 - accuracy: 0.8637 - val_loss: 0.4493 - val_accuracy: 0.8150\n",
            "Epoch 349/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3180 - accuracy: 0.8637 - val_loss: 0.4498 - val_accuracy: 0.8173\n",
            "Epoch 350/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3171 - accuracy: 0.8650 - val_loss: 0.4518 - val_accuracy: 0.8191\n",
            "Epoch 351/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3168 - accuracy: 0.8648 - val_loss: 0.4467 - val_accuracy: 0.8222\n",
            "Epoch 352/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3155 - accuracy: 0.8667 - val_loss: 0.4538 - val_accuracy: 0.8195\n",
            "Epoch 353/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3170 - accuracy: 0.8628 - val_loss: 0.4491 - val_accuracy: 0.8195\n",
            "Epoch 354/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3179 - accuracy: 0.8643 - val_loss: 0.4486 - val_accuracy: 0.8213\n",
            "Epoch 355/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3175 - accuracy: 0.8637 - val_loss: 0.4512 - val_accuracy: 0.8159\n",
            "Epoch 356/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3172 - accuracy: 0.8618 - val_loss: 0.4508 - val_accuracy: 0.8168\n",
            "Epoch 357/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3167 - accuracy: 0.8655 - val_loss: 0.4508 - val_accuracy: 0.8191\n",
            "Epoch 358/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3166 - accuracy: 0.8647 - val_loss: 0.4668 - val_accuracy: 0.8079\n",
            "Epoch 359/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3183 - accuracy: 0.8626 - val_loss: 0.4522 - val_accuracy: 0.8159\n",
            "Epoch 360/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3172 - accuracy: 0.8635 - val_loss: 0.4476 - val_accuracy: 0.8195\n",
            "Epoch 361/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3188 - accuracy: 0.8646 - val_loss: 0.4502 - val_accuracy: 0.8173\n",
            "Epoch 362/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3165 - accuracy: 0.8610 - val_loss: 0.4527 - val_accuracy: 0.8173\n",
            "Epoch 363/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3180 - accuracy: 0.8638 - val_loss: 0.4511 - val_accuracy: 0.8191\n",
            "Epoch 364/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3170 - accuracy: 0.8652 - val_loss: 0.4513 - val_accuracy: 0.8200\n",
            "Epoch 365/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3168 - accuracy: 0.8638 - val_loss: 0.4538 - val_accuracy: 0.8137\n",
            "Epoch 366/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3163 - accuracy: 0.8653 - val_loss: 0.4530 - val_accuracy: 0.8177\n",
            "Epoch 367/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3190 - accuracy: 0.8635 - val_loss: 0.4546 - val_accuracy: 0.8142\n",
            "Epoch 368/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3166 - accuracy: 0.8639 - val_loss: 0.4496 - val_accuracy: 0.8195\n",
            "Epoch 369/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3165 - accuracy: 0.8638 - val_loss: 0.4572 - val_accuracy: 0.8146\n",
            "Epoch 370/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3167 - accuracy: 0.8642 - val_loss: 0.4504 - val_accuracy: 0.8159\n",
            "Epoch 371/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3153 - accuracy: 0.8653 - val_loss: 0.4508 - val_accuracy: 0.8177\n",
            "Epoch 372/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3162 - accuracy: 0.8630 - val_loss: 0.4511 - val_accuracy: 0.8209\n",
            "Epoch 373/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3161 - accuracy: 0.8627 - val_loss: 0.4532 - val_accuracy: 0.8164\n",
            "Epoch 374/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3165 - accuracy: 0.8639 - val_loss: 0.4508 - val_accuracy: 0.8182\n",
            "Epoch 375/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3164 - accuracy: 0.8655 - val_loss: 0.4547 - val_accuracy: 0.8164\n",
            "Epoch 376/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3177 - accuracy: 0.8611 - val_loss: 0.4627 - val_accuracy: 0.8115\n",
            "Epoch 377/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3173 - accuracy: 0.8640 - val_loss: 0.4510 - val_accuracy: 0.8182\n",
            "Epoch 378/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3156 - accuracy: 0.8655 - val_loss: 0.4498 - val_accuracy: 0.8182\n",
            "Epoch 379/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3158 - accuracy: 0.8631 - val_loss: 0.4458 - val_accuracy: 0.8209\n",
            "Epoch 380/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3160 - accuracy: 0.8655 - val_loss: 0.4504 - val_accuracy: 0.8195\n",
            "Epoch 381/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3159 - accuracy: 0.8664 - val_loss: 0.4459 - val_accuracy: 0.8204\n",
            "Epoch 382/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3156 - accuracy: 0.8630 - val_loss: 0.4508 - val_accuracy: 0.8159\n",
            "Epoch 383/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3148 - accuracy: 0.8638 - val_loss: 0.4470 - val_accuracy: 0.8177\n",
            "Epoch 384/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3161 - accuracy: 0.8646 - val_loss: 0.4514 - val_accuracy: 0.8191\n",
            "Epoch 385/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3151 - accuracy: 0.8645 - val_loss: 0.4513 - val_accuracy: 0.8177\n",
            "Epoch 386/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3155 - accuracy: 0.8652 - val_loss: 0.4566 - val_accuracy: 0.8177\n",
            "Epoch 387/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3156 - accuracy: 0.8648 - val_loss: 0.4582 - val_accuracy: 0.8164\n",
            "Epoch 388/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3153 - accuracy: 0.8643 - val_loss: 0.4497 - val_accuracy: 0.8164\n",
            "Epoch 389/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3149 - accuracy: 0.8629 - val_loss: 0.4531 - val_accuracy: 0.8146\n",
            "Epoch 390/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3155 - accuracy: 0.8636 - val_loss: 0.4563 - val_accuracy: 0.8164\n",
            "Epoch 391/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3157 - accuracy: 0.8640 - val_loss: 0.4596 - val_accuracy: 0.8119\n",
            "Epoch 392/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3158 - accuracy: 0.8638 - val_loss: 0.4544 - val_accuracy: 0.8150\n",
            "Epoch 393/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3151 - accuracy: 0.8645 - val_loss: 0.4616 - val_accuracy: 0.8106\n",
            "Epoch 394/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3149 - accuracy: 0.8649 - val_loss: 0.4524 - val_accuracy: 0.8173\n",
            "Epoch 395/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3156 - accuracy: 0.8629 - val_loss: 0.4575 - val_accuracy: 0.8137\n",
            "Epoch 396/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3156 - accuracy: 0.8648 - val_loss: 0.4527 - val_accuracy: 0.8168\n",
            "Epoch 397/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3158 - accuracy: 0.8648 - val_loss: 0.4590 - val_accuracy: 0.8182\n",
            "Epoch 398/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3147 - accuracy: 0.8636 - val_loss: 0.4505 - val_accuracy: 0.8182\n",
            "Epoch 399/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3151 - accuracy: 0.8654 - val_loss: 0.4560 - val_accuracy: 0.8177\n",
            "Epoch 400/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3158 - accuracy: 0.8628 - val_loss: 0.4543 - val_accuracy: 0.8164\n",
            "Epoch 401/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3165 - accuracy: 0.8629 - val_loss: 0.4522 - val_accuracy: 0.8209\n",
            "Epoch 402/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3149 - accuracy: 0.8653 - val_loss: 0.4558 - val_accuracy: 0.8168\n",
            "Epoch 403/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3146 - accuracy: 0.8624 - val_loss: 0.4545 - val_accuracy: 0.8159\n",
            "Epoch 404/500\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 0.3142 - accuracy: 0.8662 - val_loss: 0.4593 - val_accuracy: 0.8146\n",
            "Epoch 405/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3152 - accuracy: 0.8643 - val_loss: 0.4568 - val_accuracy: 0.8155\n",
            "Epoch 406/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3150 - accuracy: 0.8638 - val_loss: 0.4500 - val_accuracy: 0.8218\n",
            "Epoch 407/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3145 - accuracy: 0.8639 - val_loss: 0.4545 - val_accuracy: 0.8137\n",
            "Epoch 408/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3144 - accuracy: 0.8658 - val_loss: 0.4514 - val_accuracy: 0.8168\n",
            "Epoch 409/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3153 - accuracy: 0.8646 - val_loss: 0.4539 - val_accuracy: 0.8191\n",
            "Epoch 410/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3157 - accuracy: 0.8656 - val_loss: 0.4549 - val_accuracy: 0.8191\n",
            "Epoch 411/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3151 - accuracy: 0.8652 - val_loss: 0.4533 - val_accuracy: 0.8182\n",
            "Epoch 412/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3145 - accuracy: 0.8646 - val_loss: 0.4569 - val_accuracy: 0.8159\n",
            "Epoch 413/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3141 - accuracy: 0.8674 - val_loss: 0.4520 - val_accuracy: 0.8191\n",
            "Epoch 414/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3139 - accuracy: 0.8662 - val_loss: 0.4482 - val_accuracy: 0.8186\n",
            "Epoch 415/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3146 - accuracy: 0.8652 - val_loss: 0.4633 - val_accuracy: 0.8092\n",
            "Epoch 416/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3142 - accuracy: 0.8642 - val_loss: 0.4605 - val_accuracy: 0.8155\n",
            "Epoch 417/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3145 - accuracy: 0.8656 - val_loss: 0.4550 - val_accuracy: 0.8173\n",
            "Epoch 418/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3138 - accuracy: 0.8652 - val_loss: 0.4568 - val_accuracy: 0.8182\n",
            "Epoch 419/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3154 - accuracy: 0.8642 - val_loss: 0.4569 - val_accuracy: 0.8186\n",
            "Epoch 420/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3142 - accuracy: 0.8696 - val_loss: 0.4578 - val_accuracy: 0.8159\n",
            "Epoch 421/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3134 - accuracy: 0.8658 - val_loss: 0.4541 - val_accuracy: 0.8186\n",
            "Epoch 422/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3140 - accuracy: 0.8647 - val_loss: 0.4601 - val_accuracy: 0.8110\n",
            "Epoch 423/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3135 - accuracy: 0.8644 - val_loss: 0.4547 - val_accuracy: 0.8150\n",
            "Epoch 424/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3144 - accuracy: 0.8644 - val_loss: 0.4545 - val_accuracy: 0.8150\n",
            "Epoch 425/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3137 - accuracy: 0.8662 - val_loss: 0.4531 - val_accuracy: 0.8164\n",
            "Epoch 426/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3143 - accuracy: 0.8639 - val_loss: 0.4559 - val_accuracy: 0.8227\n",
            "Epoch 427/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3141 - accuracy: 0.8656 - val_loss: 0.4610 - val_accuracy: 0.8150\n",
            "Epoch 428/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3139 - accuracy: 0.8667 - val_loss: 0.4520 - val_accuracy: 0.8186\n",
            "Epoch 429/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3147 - accuracy: 0.8647 - val_loss: 0.4624 - val_accuracy: 0.8164\n",
            "Epoch 430/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3143 - accuracy: 0.8661 - val_loss: 0.4533 - val_accuracy: 0.8159\n",
            "Epoch 431/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3133 - accuracy: 0.8657 - val_loss: 0.4555 - val_accuracy: 0.8173\n",
            "Epoch 432/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3133 - accuracy: 0.8684 - val_loss: 0.4601 - val_accuracy: 0.8146\n",
            "Epoch 433/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3140 - accuracy: 0.8640 - val_loss: 0.4567 - val_accuracy: 0.8164\n",
            "Epoch 434/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3126 - accuracy: 0.8672 - val_loss: 0.4551 - val_accuracy: 0.8191\n",
            "Epoch 435/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3133 - accuracy: 0.8659 - val_loss: 0.4571 - val_accuracy: 0.8168\n",
            "Epoch 436/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3138 - accuracy: 0.8659 - val_loss: 0.4570 - val_accuracy: 0.8150\n",
            "Epoch 437/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3148 - accuracy: 0.8644 - val_loss: 0.4562 - val_accuracy: 0.8150\n",
            "Epoch 438/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3130 - accuracy: 0.8664 - val_loss: 0.4626 - val_accuracy: 0.8124\n",
            "Epoch 439/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3131 - accuracy: 0.8667 - val_loss: 0.4574 - val_accuracy: 0.8137\n",
            "Epoch 440/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3139 - accuracy: 0.8644 - val_loss: 0.4657 - val_accuracy: 0.8101\n",
            "Epoch 441/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3134 - accuracy: 0.8652 - val_loss: 0.4576 - val_accuracy: 0.8182\n",
            "Epoch 442/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3125 - accuracy: 0.8664 - val_loss: 0.4568 - val_accuracy: 0.8173\n",
            "Epoch 443/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3135 - accuracy: 0.8670 - val_loss: 0.4573 - val_accuracy: 0.8146\n",
            "Epoch 444/500\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 0.3126 - accuracy: 0.8680 - val_loss: 0.4606 - val_accuracy: 0.8177\n",
            "Epoch 445/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3134 - accuracy: 0.8648 - val_loss: 0.4634 - val_accuracy: 0.8137\n",
            "Epoch 446/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3138 - accuracy: 0.8668 - val_loss: 0.4597 - val_accuracy: 0.8115\n",
            "Epoch 447/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3135 - accuracy: 0.8649 - val_loss: 0.4615 - val_accuracy: 0.8110\n",
            "Epoch 448/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3132 - accuracy: 0.8646 - val_loss: 0.4566 - val_accuracy: 0.8195\n",
            "Epoch 449/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3120 - accuracy: 0.8647 - val_loss: 0.4615 - val_accuracy: 0.8119\n",
            "Epoch 450/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3134 - accuracy: 0.8658 - val_loss: 0.4600 - val_accuracy: 0.8146\n",
            "Epoch 451/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3139 - accuracy: 0.8640 - val_loss: 0.4575 - val_accuracy: 0.8133\n",
            "Epoch 452/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3140 - accuracy: 0.8644 - val_loss: 0.4587 - val_accuracy: 0.8159\n",
            "Epoch 453/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3131 - accuracy: 0.8648 - val_loss: 0.4534 - val_accuracy: 0.8133\n",
            "Epoch 454/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3127 - accuracy: 0.8672 - val_loss: 0.4552 - val_accuracy: 0.8209\n",
            "Epoch 455/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3115 - accuracy: 0.8655 - val_loss: 0.4636 - val_accuracy: 0.8083\n",
            "Epoch 456/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3136 - accuracy: 0.8658 - val_loss: 0.4556 - val_accuracy: 0.8150\n",
            "Epoch 457/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3126 - accuracy: 0.8668 - val_loss: 0.4602 - val_accuracy: 0.8164\n",
            "Epoch 458/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3135 - accuracy: 0.8656 - val_loss: 0.4621 - val_accuracy: 0.8142\n",
            "Epoch 459/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3120 - accuracy: 0.8672 - val_loss: 0.4543 - val_accuracy: 0.8150\n",
            "Epoch 460/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3130 - accuracy: 0.8681 - val_loss: 0.4605 - val_accuracy: 0.8173\n",
            "Epoch 461/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3122 - accuracy: 0.8667 - val_loss: 0.4583 - val_accuracy: 0.8177\n",
            "Epoch 462/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3138 - accuracy: 0.8655 - val_loss: 0.4619 - val_accuracy: 0.8146\n",
            "Epoch 463/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3129 - accuracy: 0.8666 - val_loss: 0.4592 - val_accuracy: 0.8159\n",
            "Epoch 464/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3139 - accuracy: 0.8681 - val_loss: 0.4628 - val_accuracy: 0.8186\n",
            "Epoch 465/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3122 - accuracy: 0.8668 - val_loss: 0.4607 - val_accuracy: 0.8128\n",
            "Epoch 466/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3115 - accuracy: 0.8656 - val_loss: 0.4632 - val_accuracy: 0.8092\n",
            "Epoch 467/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3127 - accuracy: 0.8659 - val_loss: 0.4654 - val_accuracy: 0.8115\n",
            "Epoch 468/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3125 - accuracy: 0.8655 - val_loss: 0.4616 - val_accuracy: 0.8115\n",
            "Epoch 469/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3126 - accuracy: 0.8662 - val_loss: 0.4573 - val_accuracy: 0.8173\n",
            "Epoch 470/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3123 - accuracy: 0.8658 - val_loss: 0.4582 - val_accuracy: 0.8159\n",
            "Epoch 471/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3121 - accuracy: 0.8682 - val_loss: 0.4557 - val_accuracy: 0.8155\n",
            "Epoch 472/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3115 - accuracy: 0.8677 - val_loss: 0.4603 - val_accuracy: 0.8150\n",
            "Epoch 473/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3116 - accuracy: 0.8683 - val_loss: 0.4619 - val_accuracy: 0.8110\n",
            "Epoch 474/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3127 - accuracy: 0.8681 - val_loss: 0.4594 - val_accuracy: 0.8124\n",
            "Epoch 475/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3127 - accuracy: 0.8653 - val_loss: 0.4589 - val_accuracy: 0.8173\n",
            "Epoch 476/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3128 - accuracy: 0.8685 - val_loss: 0.4552 - val_accuracy: 0.8133\n",
            "Epoch 477/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3130 - accuracy: 0.8673 - val_loss: 0.4536 - val_accuracy: 0.8164\n",
            "Epoch 478/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3118 - accuracy: 0.8665 - val_loss: 0.4682 - val_accuracy: 0.8115\n",
            "Epoch 479/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3116 - accuracy: 0.8659 - val_loss: 0.4670 - val_accuracy: 0.8065\n",
            "Epoch 480/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3116 - accuracy: 0.8662 - val_loss: 0.4601 - val_accuracy: 0.8150\n",
            "Epoch 481/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3116 - accuracy: 0.8705 - val_loss: 0.4590 - val_accuracy: 0.8137\n",
            "Epoch 482/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3119 - accuracy: 0.8658 - val_loss: 0.4625 - val_accuracy: 0.8195\n",
            "Epoch 483/500\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 0.3126 - accuracy: 0.8668 - val_loss: 0.4671 - val_accuracy: 0.8119\n",
            "Epoch 484/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3129 - accuracy: 0.8666 - val_loss: 0.4585 - val_accuracy: 0.8128\n",
            "Epoch 485/500\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 0.3126 - accuracy: 0.8650 - val_loss: 0.4677 - val_accuracy: 0.8106\n",
            "Epoch 486/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3131 - accuracy: 0.8668 - val_loss: 0.4569 - val_accuracy: 0.8164\n",
            "Epoch 487/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3124 - accuracy: 0.8662 - val_loss: 0.4580 - val_accuracy: 0.8133\n",
            "Epoch 488/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3121 - accuracy: 0.8654 - val_loss: 0.4602 - val_accuracy: 0.8155\n",
            "Epoch 489/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3113 - accuracy: 0.8650 - val_loss: 0.4581 - val_accuracy: 0.8133\n",
            "Epoch 490/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3115 - accuracy: 0.8670 - val_loss: 0.4597 - val_accuracy: 0.8186\n",
            "Epoch 491/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3108 - accuracy: 0.8689 - val_loss: 0.4609 - val_accuracy: 0.8124\n",
            "Epoch 492/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3114 - accuracy: 0.8638 - val_loss: 0.4562 - val_accuracy: 0.8142\n",
            "Epoch 493/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3123 - accuracy: 0.8668 - val_loss: 0.4616 - val_accuracy: 0.8133\n",
            "Epoch 494/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3121 - accuracy: 0.8668 - val_loss: 0.4571 - val_accuracy: 0.8146\n",
            "Epoch 495/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3107 - accuracy: 0.8681 - val_loss: 0.4542 - val_accuracy: 0.8195\n",
            "Epoch 496/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3118 - accuracy: 0.8653 - val_loss: 0.4625 - val_accuracy: 0.8164\n",
            "Epoch 497/500\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 0.3117 - accuracy: 0.8659 - val_loss: 0.4602 - val_accuracy: 0.8137\n",
            "Epoch 498/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3117 - accuracy: 0.8676 - val_loss: 0.4638 - val_accuracy: 0.8173\n",
            "Epoch 499/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3114 - accuracy: 0.8658 - val_loss: 0.4689 - val_accuracy: 0.8092\n",
            "Epoch 500/500\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.3121 - accuracy: 0.8672 - val_loss: 0.4615 - val_accuracy: 0.8124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history.history.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J46TXjG9C3mF",
        "outputId": "94c5e9d5-0abc-4cb0-8cef-de0bdecacc42"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "_ukO0NkeC6Ql",
        "outputId": "b620755e-ed5c-4267-d95f-3754f6a3cfd8"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "_, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
        "print('train acuracy: ', train_acc)\n",
        "_, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('test acuracy: ', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3gNw9OzC8vM",
        "outputId": "155415c0-67df-4fed-a2ba-8ad7d41f122a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train acuracy:  0.8719901442527771\n",
            "test acuracy:  0.8123600482940674\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM"
      ],
      "metadata": {
        "id": "xClWWd-CFVQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import svm model\n",
        "from sklearn import svm\n",
        "\n",
        "#Create a svm Classifier\n",
        "clf = svm.SVC(kernel='rbf') # Linear Kernel\n",
        "\n",
        "#Train the model using the training sets\n",
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "KS5vDUMDFY_2",
        "outputId": "dfce7f3f-30be-45de-b8e7-45747630a1ad"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a svm Classifier\n",
        "clf = svm.SVC(kernel='linear',C=1) # Linear Kernel\n",
        "\n",
        "#Train the model using the training sets\n",
        "clf.fit(X_train, y_train)\n",
        "print('train acc: ', clf.score(X_train, y_train))\n",
        "print('test acc: ', clf.score(X_test, y_test))\n",
        "y_pred = clf.predict(X_test)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zFoWbh8FgnW",
        "outputId": "17a55166-a3a8-48e7-88b7-99907674e278"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train acc:  0.7997536118266323\n",
            "test acc:  0.800268696820421\n",
            "[[978 209]\n",
            " [237 809]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.82      0.81      1187\n",
            "           1       0.79      0.77      0.78      1046\n",
            "\n",
            "    accuracy                           0.80      2233\n",
            "   macro avg       0.80      0.80      0.80      2233\n",
            "weighted avg       0.80      0.80      0.80      2233\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a svm Classifier\n",
        "clf = svm.SVC(kernel='rbf',C=0.5,gamma=1) # Linear Kernel\n",
        "\n",
        "#Train the model using the training sets\n",
        "clf.fit(X_train, y_train)\n",
        "print('train acc: ', clf.score(X_train, y_train))\n",
        "print('test acc: ', clf.score(X_test, y_test))\n",
        "y_pred = clf.predict(X_test)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9Ey7T5-FnI9",
        "outputId": "3648710f-073f-4181-edb1-b7d8380b62d0"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train acc:  0.9536342255571733\n",
            "test acc:  0.7241379310344828\n",
            "[[675 512]\n",
            " [104 942]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.57      0.69      1187\n",
            "           1       0.65      0.90      0.75      1046\n",
            "\n",
            "    accuracy                           0.72      2233\n",
            "   macro avg       0.76      0.73      0.72      2233\n",
            "weighted avg       0.76      0.72      0.72      2233\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN"
      ],
      "metadata": {
        "id": "wnnM7ZMeFu68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier = KNeighborsClassifier(n_neighbors=3)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "hp7mpqI-FwZr",
        "outputId": "6bfe1c46-242b-461a-d552-a92621e02a09"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(n_neighbors=3)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=3)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Prediction on Testing samples\n",
        "y_pred = classifier.predict(X_test)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrQq_JJRF1K6",
        "outputId": "892f6ce6-2874-4630-e597-c1547ccfe373"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 1, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.score(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1r7iBZJF3g7",
        "outputId": "fd2f86fc-be36-4e82-ef65-de27cedac5e6"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8729980960913876"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DM0x918ZF6oq",
        "outputId": "6570d84b-b56d-4ee3-b8f3-55c4407b430a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7657859381997313"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN6hoGX3F9Gj",
        "outputId": "b011e9a1-c2a8-4944-ba31-e3ea22e369b2"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[959 228]\n",
            " [295 751]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.81      0.79      1187\n",
            "           1       0.77      0.72      0.74      1046\n",
            "\n",
            "    accuracy                           0.77      2233\n",
            "   macro avg       0.77      0.76      0.76      2233\n",
            "weighted avg       0.77      0.77      0.77      2233\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPagD34hGARq",
        "outputId": "0f5ba3c0-bf9f-4621-b579-8a36ac781e80"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7417283950617284"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Observations & Final Report:\n",
        "\n",
        "<table><tr><th>Model Name</th><th>Training Accuracy</th><th>Test Accuracy</th></tr><tbody><tr><td>ANN</td><td>87.2</td><td>81.2</td></tr><tr><td>SVM</td><td>95.3</td><td>72.4</td></tr><tr><td>KNN</td><td>87.3</td><td>76.5</td></tr></tbody></table>\n",
        "\n",
        "**After comparing above results, ANN seems to be best model for this project**"
      ],
      "metadata": {
        "id": "s0kBF2GUGCii"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}